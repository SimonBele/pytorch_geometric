{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_version = str(torch.__version__)\n",
    "# scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "# sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "# !pip install torch-scatter -f $scatter_src\n",
    "# !pip install torch-sparse -f $sparse_src\n",
    "# !pip install torch-geometric\n",
    "# !pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.data import DataLoader, Data, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch_geometric.nn import GCNConv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cyclic dataset has 13081 graphs\n",
      "The acyclic dataset has 13759 graphs\n"
     ]
    }
   ],
   "source": [
    "class AcyclicGraphDataset(Dataset):\n",
    "    def __init__(self, pyg_dataset):\n",
    "        super(AcyclicGraphDataset, self).__init__()\n",
    "        self.pyg_dataset = pyg_dataset\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.pyg_dataset)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.pyg_dataset[idx]\n",
    "\n",
    "class CyclicGraphDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CyclicGraphDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "cyclic_dataset = torch.load(\"cyclic_dataset.pt\")\n",
    "acyclic_dataset = torch.load(\"acyclic_dataset.pt\")\n",
    "print('The {} dataset has {} graphs'.format(\"cyclic\", len(cyclic_dataset)))\n",
    "print('The {} dataset has {} graphs'.format(\"acyclic\", len(acyclic_dataset)))\n",
    "cyclic_data = cyclic_dataset[0]\n",
    "acyclic_data = acyclic_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class IsAcyclic(Dataset):\n",
    "    def __init__(self, cyclic_data, acyclic_data):\n",
    "        super(IsAcyclic, self).__init__()\n",
    "        self.cyclic_data = cyclic_data\n",
    "        self.acyclic_data = acyclic_data\n",
    "        # Combine the two datasets\n",
    "        \n",
    "        self.data_list = [(data, 0) for data in cyclic_data] + [(data, 1) for data in acyclic_data]\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data, label = self.data_list[idx]\n",
    "        # Ensure the label is a tensor and attach it to the data object\n",
    "        data.y = torch.tensor([label], dtype=torch.float)\n",
    "        return data\n",
    "\n",
    "    def get_idx_split(self, train_ratio=0.7, val_ratio=0.15):\n",
    "        def split_indices(data, train_ratio, val_ratio):\n",
    "            dataset_size = len(data)\n",
    "            indices = list(range(dataset_size))\n",
    "            random.shuffle(indices)\n",
    "\n",
    "            train_split = int(train_ratio * dataset_size)\n",
    "            val_split = int(val_ratio * dataset_size) + train_split\n",
    "\n",
    "            return indices[:train_split], indices[train_split:val_split], indices[val_split:]\n",
    "\n",
    "        # Split cyclic and acyclic datasets separately\n",
    "        cyclic_train, cyclic_val, cyclic_test = split_indices(self.cyclic_data, train_ratio, val_ratio)\n",
    "        acyclic_train, acyclic_val, acyclic_test = split_indices(self.acyclic_data, train_ratio, val_ratio)\n",
    "\n",
    "        # Offset acyclic indices by the size of cyclic dataset\n",
    "        offset = len(self.cyclic_data)\n",
    "        acyclic_train = [i + offset for i in acyclic_train]\n",
    "        acyclic_val = [i + offset for i in acyclic_val]\n",
    "        acyclic_test = [i + offset for i in acyclic_test]\n",
    "\n",
    "        # Combine the splits from cyclic and acyclic datasets\n",
    "        train_indices = cyclic_train + acyclic_train\n",
    "        val_indices = cyclic_val + acyclic_val\n",
    "        test_indices = cyclic_test + acyclic_test\n",
    "\n",
    "        # Shuffle combined splits to mix cyclic and acyclic graphs\n",
    "        random.shuffle(train_indices)\n",
    "        random.shuffle(val_indices)\n",
    "        random.shuffle(test_indices)\n",
    "\n",
    "        return {\n",
    "            'train': train_indices,\n",
    "            'valid': val_indices,\n",
    "            'test': test_indices\n",
    "        }\n",
    "\n",
    "\n",
    "# Assuming 'cyclic_dataset' and 'acyclic_dataset' are already created as per your provided code\n",
    "dataset = IsAcyclic(cyclic_dataset, acyclic_dataset)\n",
    "\n",
    "torch.save(dataset, 'is_acyclic.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\Miniconda3\\envs\\research\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': device,\n",
    "    'input_dim' : 1,\n",
    "    'gcn_output_dim' : [8, 16],\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'weight_decay' : 0.00001,\n",
    "    'epochs': 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the node degrees as the initial features for all nodes.\n",
    "# Then we apply two layers of GCNs with output dimensions\n",
    "# equal to 8, 16 respectively and perform global averaging to obtain\n",
    "# the graph representations. Finally, we employ one fully-connected\n",
    "# layer as the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a101562d599c4f80b2d4b28eb324de3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 01, Loss: 0.1767, Train Acc: 83.24%, Valid Acc: 83.93% Test Acc: 82.57%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9591fedd7fc644b18f164e4f50e69e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 02, Loss: 0.2097, Train Acc: 82.96%, Valid Acc: 83.80% Test Acc: 82.27%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247325deecdc4f25bc9432550effd8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 03, Loss: 0.1271, Train Acc: 83.29%, Valid Acc: 83.93% Test Acc: 82.55%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3a255c9a08461fb3c5a9c4b492730d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 04, Loss: 0.8971, Train Acc: 83.29%, Valid Acc: 84.07% Test Acc: 82.55%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76a694d0a664f6090ee37930e4789d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 05, Loss: 0.4581, Train Acc: 82.99%, Valid Acc: 83.73% Test Acc: 82.30%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b214c61cbef483ea088baf757313a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 06, Loss: 0.5921, Train Acc: 82.02%, Valid Acc: 83.18% Test Acc: 81.06%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6362fd9a67b54696acf207ea5376d938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 07, Loss: 0.4054, Train Acc: 83.50%, Valid Acc: 84.15% Test Acc: 82.57%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491301b560c84b2c9bb1ee85e4d03c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 08, Loss: 0.1448, Train Acc: 82.95%, Valid Acc: 83.98% Test Acc: 82.27%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741f60800aa746ebbed9652e602e0d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 09, Loss: 0.3150, Train Acc: 82.97%, Valid Acc: 84.00% Test Acc: 81.78%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e33cd008b148398fc016ced73f6546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 10, Loss: 0.2481, Train Acc: 83.59%, Valid Acc: 83.98% Test Acc: 82.60%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf43964017a04cb8b93202424ee2a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 11, Loss: 0.3956, Train Acc: 83.27%, Valid Acc: 84.10% Test Acc: 82.55%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b5c512234642b39ace84daf6ce759e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 12, Loss: 0.4177, Train Acc: 78.95%, Valid Acc: 80.30% Test Acc: 78.60%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fafe8b04ddc436ca707d68f23eb50df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 13, Loss: 1.4654, Train Acc: 83.15%, Valid Acc: 83.88% Test Acc: 82.42%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4bde8ef60344a8b2384eef9f4fc867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 14, Loss: 0.8676, Train Acc: 83.28%, Valid Acc: 84.20% Test Acc: 82.52%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5419fa538ef545c6b63f1748d5b2cd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 15, Loss: 0.8861, Train Acc: 81.92%, Valid Acc: 82.14% Test Acc: 81.43%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5791c11bd0c43318deebe3e68beb6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 16, Loss: 0.0780, Train Acc: 83.45%, Valid Acc: 84.27% Test Acc: 82.77%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a54fdbbdcb24d9da5fc43bf5e6ba0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 17, Loss: 0.5209, Train Acc: 83.12%, Valid Acc: 83.73% Test Acc: 82.17%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2db2e4ab95477798226c1881a8c511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 18, Loss: 0.7682, Train Acc: 82.84%, Valid Acc: 83.60% Test Acc: 82.13%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2fe78367e142f9aecc4ba848ce6550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 19, Loss: 1.3003, Train Acc: 83.21%, Valid Acc: 84.07% Test Acc: 82.32%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d80e8e42136453f80fe068c0a656000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 20, Loss: 0.3042, Train Acc: 83.46%, Valid Acc: 84.17% Test Acc: 82.57%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca08d349cd041318d45aaa9ad4cb873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 21, Loss: 0.2948, Train Acc: 83.34%, Valid Acc: 83.98% Test Acc: 82.42%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0378c1297c46e5b8e220ecf30e8e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 22, Loss: 0.2855, Train Acc: 83.31%, Valid Acc: 83.90% Test Acc: 82.40%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e871f878e20a402c8371ab66bd136264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 23, Loss: 0.6934, Train Acc: 83.43%, Valid Acc: 84.17% Test Acc: 82.45%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b9a75427dc4bccb91d10cbf3aa7169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 24, Loss: 0.9340, Train Acc: 83.15%, Valid Acc: 83.80% Test Acc: 82.40%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf2d02c9e5b42afa87cb44ca5105a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 25, Loss: 0.4872, Train Acc: 83.49%, Valid Acc: 84.20% Test Acc: 82.65%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb698195c1ec47b4b66af6489fa0dda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 26, Loss: 1.0675, Train Acc: 83.03%, Valid Acc: 83.68% Test Acc: 82.10%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391620b97969461387b9dce5356f2b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 27, Loss: 0.3447, Train Acc: 83.37%, Valid Acc: 84.32% Test Acc: 82.80%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae0ad137a944b91ac171726cbe8ee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 28, Loss: 0.5902, Train Acc: 83.30%, Valid Acc: 84.00% Test Acc: 82.35%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1998aaaf77d341e19a4545fa6aac837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 29, Loss: 0.1217, Train Acc: 83.54%, Valid Acc: 84.20% Test Acc: 82.55%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee6c70e248b4825a54426547a01cc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch: 30, Loss: 0.2691, Train Acc: 83.21%, Valid Acc: 83.90% Test Acc: 82.37%\n",
      "Best model: Train: 83.37%, Valid: 84.32% Test: 82.80%\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, gcn_output_dims, dropout, return_embeds=False):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels=input_dim, out_channels=gcn_output_dims[0])])\n",
    "        self.convs.extend([GCNConv(in_channels=gcn_output_dims[i + 0], out_channels=gcn_output_dims[i + 1]) for i in range(len(gcn_output_dims) - 1)])\n",
    "\n",
    "        self.bns = torch.nn.ModuleList([BatchNorm1d(num_features=gcn_output_dims[l]) for l in range(len(gcn_output_dims) - 1)])\n",
    "        \n",
    "        self.softmax = torch.nn.LogSoftmax()\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        out = None\n",
    "\n",
    "        for i in range(len(self.convs)-1):\n",
    "          x = F.relu(self.bns[i](self.convs[i](x, adj_t)))\n",
    "          if self.training:\n",
    "            x = F.dropout(x, p=self.dropout)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        if self.return_embeds:\n",
    "          out = x\n",
    "        else:\n",
    "          out = self.softmax(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "### GCN to predict graph property\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, input_dim, gcn_output_dims, output_dim, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # self.node_encoder = AtomEncoder(hidden_dim)\n",
    "        \n",
    "        self.gnn_node = GCN(input_dim, gcn_output_dims, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = global_mean_pool # global averaging to obtain graph representation\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = torch.nn.Linear(gcn_output_dims[-1], output_dim) # One fully connected layer as a classifier\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      self.gnn_node.reset_parameters()\n",
    "      self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        # Extract important attributes of our mini-batch\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        \n",
    "        device = edge_index.device\n",
    "        degrees = torch.sum(edge_index[0] == torch.arange(edge_index.max() + 1, device=device)[:, None], dim=1, dtype=torch.float)\n",
    "        x = degrees.unsqueeze(1)  # Add feature dimension\n",
    "        embed = x.to(device)  # Ensure the embedding tensor is on the correct device\n",
    "\n",
    "        out = None\n",
    "\n",
    "        node_embeddings = self.gnn_node(embed, edge_index)\n",
    "        agg_features = self.pool(node_embeddings, batch)\n",
    "        out = self.linear(agg_features)\n",
    "\n",
    "        return out\n",
    "\n",
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "      batch = batch.to(device)\n",
    "\n",
    "      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "          pass\n",
    "      else:\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "        is_labeled = batch.y == batch.y\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        filtered_output = out[is_labeled]\n",
    "\n",
    "        # Reshape the labels to match the output shape\n",
    "        filtered_labels = batch.y[is_labeled].unsqueeze(1).type(torch.float32)\n",
    "\n",
    "        loss = loss_fn(filtered_output, filtered_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    # Assuming y_pred are logits; apply sigmoid and round off to get binary predictions\n",
    "    preds = torch.sigmoid(y_pred) > 0.5\n",
    "    correct = preds.eq(y_true.view_as(preds)).sum()\n",
    "    accuracy = correct.float() / y_true.numel()\n",
    "    return accuracy.item()\n",
    "\n",
    "def eval(model, device, loader):\n",
    "    model.eval()\n",
    "    total_accuracy = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "\n",
    "        # Assuming binary classification and batch.y is your ground truth\n",
    "        accuracy = compute_accuracy(batch.y, pred)\n",
    "        total_accuracy += accuracy * batch.y.size(0)\n",
    "        total_samples += batch.y.size(0)\n",
    "\n",
    "    return total_accuracy / total_samples\n",
    "\n",
    "# # The evaluation function\n",
    "# def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n",
    "#     model.eval()\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "\n",
    "#     for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "#         batch = batch.to(device)\n",
    "\n",
    "#         if batch.x.shape[0] == 1:\n",
    "#             pass\n",
    "#         else:\n",
    "#             with torch.no_grad():\n",
    "#                 pred = model(batch)\n",
    "\n",
    "#             y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "#             y_pred.append(pred.detach().cpu())\n",
    "\n",
    "#     y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "#     y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "#     input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "#     if save_model_results:\n",
    "#         print (\"Saving Model Predictions\")\n",
    "\n",
    "#         # Create a pandas dataframe with a two columns\n",
    "#         # y_pred | y_true\n",
    "#         data = {}\n",
    "#         data['y_pred'] = y_pred.reshape(-1)\n",
    "#         data['y_true'] = y_true.reshape(-1)\n",
    "\n",
    "#         df = pd.DataFrame(data=data)\n",
    "#         # Save to csv\n",
    "#         df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n",
    "\n",
    "#     return evaluator.eval(input_dict)\n",
    "\n",
    "\n",
    "model = GCN_Graph(args['input_dim'], args['gcn_output_dim'],\n",
    "            output_dim=1, dropout=args['dropout']).to(device)\n",
    "# evaluator = Evaluator(name='ogbg-molhiv')\n",
    "\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "# Training loop remains the same...\n",
    "\n",
    "# Evaluation in your main loop\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    train_loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    train_acc = eval(model, device, train_loader)\n",
    "    val_acc = eval(model, device, valid_loader)\n",
    "    test_acc = eval(model, device, test_loader)\n",
    "\n",
    "    if val_acc > best_valid_acc:\n",
    "        best_valid_acc = val_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {train_loss:.4f}, '\n",
    "          f'Train Acc: {100 * train_acc:.2f}%, '\n",
    "          f'Valid Acc: {100 * val_acc:.2f}% '\n",
    "          f'Test Acc: {100 * test_acc:.2f}%')\n",
    "\n",
    "# Evaluate the best model\n",
    "best_train_acc = eval(best_model, device, train_loader)\n",
    "best_val_acc = eval(best_model, device, valid_loader)\n",
    "best_test_acc = eval(best_model, device, test_loader)\n",
    "\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * best_train_acc:.2f}%, '\n",
    "      f'Valid: {100 * best_val_acc:.2f}% '\n",
    "      f'Test: {100 * best_test_acc:.2f}%')\n",
    "\n",
    "\n",
    "# for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "#   print('Training...')\n",
    "#   loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "#   print('Evaluating...')\n",
    "#   train_result = eval(model, device, train_loader, evaluator)\n",
    "#   val_result = eval(model, device, valid_loader, evaluator)\n",
    "#   test_result = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "#   train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
    "#   if valid_acc > best_valid_acc:\n",
    "#       best_valid_acc = valid_acc\n",
    "#       best_model = copy.deepcopy(model)\n",
    "#   print(f'Epoch: {epoch:02d}, '\n",
    "#         f'Loss: {loss:.4f}, '\n",
    "#         f'Train: {100 * train_acc:.2f}%, '\n",
    "#         f'Valid: {100 * valid_acc:.2f}% '\n",
    "#         f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "\n",
    "# train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "# valid_auroc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n",
    "# test_auroc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n",
    "\n",
    "# print(f'Best model: '\n",
    "#     f'Train: {100 * train_auroc:.2f}%, '\n",
    "#     f'Valid: {100 * valid_auroc:.2f}% '\n",
    "#     f'Test: {100 * test_auroc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a8a4b80f4f70c84f31aca617cda6666e967fece7258fbe31fedfa48a0f63f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
